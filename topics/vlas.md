# Vision-Language-Action models

In general, when working with VLAs, several important features are considered. Among the main ones are **language following**, **dexterous movements**, **long-horizon tasks**, **spatial reasoning**, **low-latency systems**, and **low-memory systems**. We have various examples of these such as [π 0.5: a VLA with Open-World Generalization](https://www.physicalintelligence.company/blog/pi05), [GR00T-N1.5](https://research.nvidia.com/labs/gear/gr00t-n1_5/) ,[arXiv:2507.15493](https://arxiv.org/abs/2507.15493)

| Tittle | Problem | Description | Future work | Date |
| - | - | - | - | - |
[π 0.5: a VLA with Open-World Generalization](https://www.physicalintelligence.company/blog/pi05) | - | Paper description | Future work description | 22/04/25 |
[GR00T-N1.5](https://research.nvidia.com/labs/gear/gr00t-n1_5/) | - | Paper description | Future work description | 11/06/25 |
[GR-3 Technical Report](https://arxiv.org/abs/2507.15493) | - | Paper description | Future work description | 22/07/25 |
[Tittle](link) | - | Paper description | Future work description | dd/mm/YY |