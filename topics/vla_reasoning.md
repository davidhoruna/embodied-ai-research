# VLA Reasoning

Another important aspect is how to improve your modelâ€™s capabilities using the same concept that emerged in LLMs: reasoning. There are several works such as Molmo ACT, where reasoning essentially consists of adding more sources of information that the VLM must predict, with discretized actions such as strokes or depth tokens. Other works, like COT VLA, focus on achieving reasoning by generating intermediate images that provide this visual information before completing a task. This is strongly related to world models.

| Tittle | Problem | Description | Future work | Date |
| - | - | - | - | - |
[CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models](https://arxiv.org/abs/2503.22020) | - | Paper description | Future work description | 27/03/25 |
[MolmoAct: Action Reasoning Models that can Reason in Space](https://arxiv.org/pdf/2508.07917) | - | Paper description | Future work description | 18/09/25 |
[Tittle](link) | - | Paper description | Future work description | dd/mm/YY |
[Tittle](link) | - | Paper description | Future work description | dd/mm/YY |